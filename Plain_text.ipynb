{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Plain-text iegūšana\n",
        "Šajā Google Collab dokumentā tiks apskatītas metodes kā veikt teksta priekšapstrādi. <br> Priekšapstrādes mērķis ir iegūt tīru tekstu no dažāda formāta dokumentiem. <br>\n",
        "Darbojoties Python vidē lielākajai daļai no populārajiem formātiem būs pieejamas bibliotēkas, kas ir meklējamas un apskatāmas PyPI. <br>\n",
        "\n"
      ],
      "metadata": {
        "id": "BbtrO9w3zVaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### HTML to Plain-text <br>\n",
        "Python vidē priekš HTML un XML formātu parsēšanas eksistē BeautifuSoup bibliotēka. <br>\n",
        "Dokumentācija atrodama: https://pypi.org/project/beautifulsoup4/ <br>\n",
        "BeautifulSoup apstrādes izsaukumam jāpadod HTML parsētājs kā atribūts. Šajā piemērā pielitoju \"lxml\" parseri. Citas parseru alternaltvas var skatīt dokumentācijā."
      ],
      "metadata": {
        "id": "mi-kondA0Eqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install BeautifulSoup\n",
        "!pip install lxml"
      ],
      "metadata": {
        "id": "IGKT3JxM9etu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "r6U6v5VezUNd"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import html\n",
        "\n",
        "# Varam veidot dažāda veida atlases pēc HTML elementa tipiem, lai atbīvotos no informācijas, kas mums nav nepieciešama.\n",
        "# Piemēram, dažkārt vēlams atbrīvoties no tabulām, ja tās satur tikai skaitliskus datus vai individuālus vārdus, bet mēs vēlams iegūt tikai pilnus teikumus.\n",
        "def remove_tables(text):\n",
        "    soup = BeautifulSoup(text, \"lxml\")\n",
        "    for table in soup.find_all(\"table\"):\n",
        "        table.decompose()\n",
        "    return str(soup)\n",
        "\n",
        "\n",
        "# Pielietojam  \"html.unescape()\", lai atbrīvotos no visa HTML marķējuma.\n",
        "# Tomēr apstrādājot HTML dokumentus nepieciešams arī pārveidod escape characters. (piemēram, &amp; -> &)\n",
        "# Ar BeautifulSoup bibliotēkas palīdzību pārveidojam šos simbolus tiem atbilstošajā plain-text\n",
        "def convert_html_char(text):\n",
        "    text = html.unescape(text)\n",
        "    text = BeautifulSoup(text, \"lxml\").text\n",
        "    return text\n",
        "\n",
        "\n",
        "def html2txt(html_file, outfile=\"output.txt\"):\n",
        "    input_file = open(html_file, \"r\", encoding=\"utf-8\")\n",
        "    text = input_file.read()\n",
        "    input_file.close()\n",
        "    text = remove_tables(text)\n",
        "    text = convert_html_char(text)\n",
        "\n",
        "    output_file = open(outfile, \"w\", encoding=\"utf-8\")\n",
        "    output_file.write(text)\n",
        "    output_file.close()\n",
        "\n",
        "\n",
        "html2txt(\"sample1.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### VERT to Plain-text <br>\n",
        "Dažkārt nākas saskarties ar formātiem, kas nav tik izplatīti pielietojumā un tiem neeksistē izstrādātas bilbliotēkas, vai arī eksistē vairāki varianti kā šis failu formāts tiek strukturizēts. Šādos gadījumos nepieciešams analizēt faila struktūru un attiecīgi iegūt un pārveidot tikai nepieciešamo informāciju. <br>**<br>**\n",
        "VERT failu formāts tiek pielietots, lai saglabātu tekstu korpusus NoSketchEngine platformā, un tas tiek pielietots arī latviešu valodas korpusiem. Informāciju par VERT formātu var skatīt vietnē: https://www.sketchengine.eu/my_keywords/vertical/ <br>\n",
        "Lai no VERT formāta iegūtu plain-text ir nepieciešams ievērot sadalīšanu teikumos un savienot visus teikuma token'us (teikuma vienības) kopā. <br>\n"
      ],
      "metadata": {
        "id": "ayvqvSpIDB_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcija vert2txt nolasa VERT failu pa rindiņām un atjauno oriģinālo plain-text teikumu.\n",
        "def vert2txt(vert_file, outfile=\"output.txt\"):\n",
        "    file = open(vert_file, \"r\", encoding=\"utf-8\")\n",
        "\n",
        "    output = open(outfile, \"a\", encoding=\"utf-8\")\n",
        "    output.truncate(0)\n",
        "\n",
        "    text = \"\"\n",
        "    while True:\n",
        "        line = file.readline()\n",
        "        if not line:\n",
        "            break\n",
        "        if line == \"\\n\":\n",
        "            if text != \"\":\n",
        "                output.write(text+\"\\n\")\n",
        "            text = \"\"\n",
        "\n",
        "        # Ja tiek nolasīts marķējuma simbols veicam attiecīgās struktūras apstrādi:\n",
        "        elif line[0] == \"<\" and line[1] != \"\\t\":\n",
        "\n",
        "            # </doc>, </p>, </s> - apzīmē dokumenta, paragrāfa, teikuma beigas\n",
        "            # pievienojam pašlaik atmiņā ielasīto teikumu izvada failam un sākam jauna teikuma nolasi.\n",
        "            if line == \"</doc>\\n\":\n",
        "                if text[:-1] == \" \":\n",
        "                    text = text[:-1]\n",
        "                text = text + \"\\n\\n\"\n",
        "                output.write(text)\n",
        "                text = \"\"\n",
        "            elif line == \"</p>\\n\":\n",
        "                if text[:-1] == \" \":\n",
        "                    text = text[:-1]\n",
        "                text = text + \"\\n\"\n",
        "                output.write(text)\n",
        "                text = \"\"\n",
        "            elif line == \"</s>\\n\":\n",
        "                if text[:-1] == \" \":\n",
        "                    text = text[:-1]\n",
        "                output.write(text)\n",
        "                text = \"\"\n",
        "\n",
        "            # <g /> - \"glue tag\" apzīmē, ka starp teikuma vienībām nav atstarpes.\n",
        "            # Tipiski starp vārdu un tam sekojošu interpunkcijas zīmi.\n",
        "            elif line == \"<g />\\n\" and len(text) > 1:\n",
        "                if text[-1] == \" \":\n",
        "                    text = text[:-1]\n",
        "\n",
        "            # Atverošos <doc>, <p>, <s> marķējumus var ignorēt\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "        # Ja rindas nesatur marķējuma simbolu tad pievienojam vārdu.\n",
        "        # Pamatojamies uz VERT struktūru, pirmais rindas elements satur vārdu tā teikumā satopamajā formā.\n",
        "        else:\n",
        "            text = text + line.split(\"\\t\")[0] + \" \"\n",
        "\n",
        "\n",
        "vert2txt(\"sample2.vert\")"
      ],
      "metadata": {
        "id": "uYnTQQW6FM7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### PDF to Plain-text <br>\n",
        "PDF formāta pārveidošana bieži vien ir sarežģīta, jo no PDF dokumenta informācijas nav iespējams viennozīmīgi iegūt teksta formatējuma un struktūras informāciju, kas bieži vien ir nepieciešama sarežģītākos PDF failos. Plašāk par problēmām var palasīt PyPDF2 bibliotēkas dokumentācijā par teksta izguvi: https://pypdf2.readthedocs.io/en/3.0.0/user/extract-text.html <br>"
      ],
      "metadata": {
        "id": "y2b4ioRTQBj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "fNOYOjaAP91t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "\n",
        "def pdf2txt(pdf_file, outfile=\"output.txt\"):\n",
        "    input_file = open(pdf_file, \"rb\")\n",
        "    reader = PdfReader(input_file)\n",
        "\n",
        "    # Izsaucam PyPDF2 lasītāju katrai PDF faila lappaspusei\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()+\"\\n\\n\"\n",
        "\n",
        "    output_file = open(outfile, \"w\", encoding=\"utf-8\")\n",
        "    output_file.write(text)\n",
        "    output_file.close()\n",
        "\n",
        "\n",
        "pdf2txt(\"sample3.pdf\")"
      ],
      "metadata": {
        "id": "YrxiI6npQSbM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iegūtajā rezultātā var manīt, ka ir vairāki PDF faila aspekti, kas neder preikš praktiski pielietojama plain-text iegūšanas. Visizteiktākā problēma ir tas, ka PDf faila teksts saglabā savu dalījumu rindās (un dalījumu lappaspusēs). Šī PDF failu nolasīšanas īpatnība nav praktiska, ja vēlamies iegūt kopu ar pilniem teikumiem, kurus analizēt. <br>\n",
        "Tādēļ, lai varētu iegūt vēlamo rezultātu, ir papildus jāveic pēcapstrāde iegūtajam plain-text failam."
      ],
      "metadata": {
        "id": "pbJPfX0hgDmk"
      }
    }
  ]
}