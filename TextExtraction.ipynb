{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Praktiskā nodarbība: Teksta izguve | Hands-on session: Text extraction\n",
        "\n",
        "Teksta korpusa izveide ir viens no priekšnoteikumiem daudzos valodas modelēšanas uzdevumos. Tā kā vienkāršs teksts (*plain-text*) bieži vien nav pieejams, nākas nodarboties ar vienkārša teksta izguvi no dokumentiem, kas pieejami citos formātos.\n",
        "\n",
        "Šajā piezīmju grāmatiņā ir apskatīti trīs vienkāršoti gadījumi teksta izguvei no dažāda formāta dokumentiem: HTML, PDF un VERT.\n",
        "\n",
        "Populārajiem dokumentu formātiem (PDF, DOCX, HTML u.c.) eksistē dažādas *Python* bibliotēkas, kuras var izmantot vienkāršā teksta izguves uzdevumam, kā tas ir nodemonstrēts šajā nodarbībā.\n",
        "\n",
        "---\n",
        "\n",
        "Creating a text corpus is one of the prerequisites for many language modeling tasks. Since plain-text is often not available, one has to deal with plain-text extraction from documents that are available in other formats.\n",
        "\n",
        "This notebook covers three simplified cases for extracting text from documents in various formats: HTML, PDF and VERT.\n",
        "\n",
        "For the popular document formats (PDF, DOCX, HTML, etc.), there are various Python libraries that can be used for the plain-text extraction task as demonstrated in this session."
      ],
      "metadata": {
        "id": "BbtrO9w3zVaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HTML-to-Text\n",
        "\n",
        "Viena no populārākajām un vienkāršāk izmantojamajām *Python* bibliotēkām HTML formāta dokumentu parsēšanai un satura \"noskrāpēšanai\" (*web scraping*) ir *BeautifulSoup* (https://pypi.org/project/beautifulsoup4/).\n",
        "\n",
        "*BeautifulSoup* savukārt izmanto zemāka līmeņa HTML/XML parsētāju: var tikt izmantots gan *Python* iebūvētais `html.parser`, gan ārējas bibliotēkas (piem., `lxml`, `html5lib`), kas nodrošina dažādas priekšrocības (piem., ātrdarbību un papildu funkcionalitāti). Šajā demonstrācijā ir izmantots iebūvētais HTML parsētājs."
      ],
      "metadata": {
        "id": "mi-kondA0Eqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4"
      ],
      "metadata": {
        "id": "IGKT3JxM9etu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39b4c15d-2ef7-4e04-e7f7-b2007d7f9e25"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O \"sample_article.html\" https://www.vti.lu.lv/par-mums/zinas/zina/t/82316/"
      ],
      "metadata": {
        "id": "TtXR-Hof8K2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55f8b13-dcb9-4fde-cdb9-99bbd81ca0e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-14 10:07:43--  https://www.vti.lu.lv/par-mums/zinas/zina/t/82316/\n",
            "Resolving www.vti.lu.lv (www.vti.lu.lv)... 5.179.1.160\n",
            "Connecting to www.vti.lu.lv (www.vti.lu.lv)|5.179.1.160|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28753 (28K) [text/html]\n",
            "Saving to: ‘sample_article.html’\n",
            "\n",
            "sample_article.html 100%[===================>]  28.08K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-02-14 10:07:44 (212 KB/s) - ‘sample_article.html’ saved [28753/28753]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "r6U6v5VezUNd"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import html\n",
        "import re\n",
        "\n",
        "\n",
        "# Funkcija veic noteikta veida HTML elementu izmešanu, lai atbīvotos no nelietderīgiem teksta blokiem.\n",
        "# Piemēri: izvēlnes, kājenes, galvenes, tabulas, kas satur tikai skaitliskus datus vai izolētus vārdus.\n",
        "# Funkciju nepieciešams pielāgot konkrēto vietņu īpatnībām, lai iegūtu iespējami kvatitatīvu teksta saturu.\n",
        "def remove_html_elements(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "\n",
        "    # Meklēšana pēc HTML elementa\n",
        "    for element in soup.find_all([\"header\", \"footer\", \"button\"]):\n",
        "        element.decompose()\n",
        "\n",
        "    # Meklēšana pēc HTML elementa ar noteiktu atribūtu\n",
        "    for element in soup.find_all([\"div\"], attrs={\"class\": re.compile(\".*([Mm]enu|share|backlink).*\")}):\n",
        "        element.decompose()\n",
        "\n",
        "    return str(soup)\n",
        "\n",
        "# Funkcija veic (1) HTML entitāšu konvertēšanu (escaped=>unescaped) un (2) HTML birku izmešanu (paturot elementu saturu).\n",
        "# Piemēri: &amp; => &, <i>vārds</i> => vārds\n",
        "# Šī funkcija ir universāla - pielietojama jebkuras vietnes satura normalizēšanai.\n",
        "def convert_html_entities(text):\n",
        "    text = html.unescape(text)                      # 1\n",
        "    text = BeautifulSoup(text, \"html.parser\").text  # 2\n",
        "    return text\n",
        "\n",
        "# Funkcija veic atstarpju un tukšo rindu normalizāciju iegūtajā vienkāršajā tekstā.\n",
        "def normalize_white_spaces(text):\n",
        "    text = re.sub(\"[ ]+\", \" \", text)\n",
        "    text = re.sub(\"[ ]?\\n+\", \"\\n\", text)\n",
        "    return text\n",
        "\n",
        "# Funkcija veic (1) lieko HTML elementu izmešanu, (2) HTML entitāšu normalizēšanu un birku izmešanu, (3) atstarpju normalizēšanu.\n",
        "def html_to_txt(html_file, txt_file):\n",
        "    input_file = open(html_file, \"r\", encoding=\"utf-8\")\n",
        "    output_file = open(txt_file, \"w\", encoding=\"utf-8\")\n",
        "\n",
        "    text = input_file.read()\n",
        "    text = remove_html_elements(text)   # 1\n",
        "    text = convert_html_entities(text)  # 2\n",
        "    text = normalize_white_spaces(text) # 3\n",
        "    output_file.write(text)\n",
        "\n",
        "    input_file.close()\n",
        "    output_file.close()\n",
        "\n",
        "\n",
        "html_to_txt(\"sample_article.html\", \"sample_article.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PDF-to-Text\n",
        "\n",
        "Saistīta teksta izguve no PDF dokumentiem lielākoties ir sarežģīta un ķēpīga: informācija par teksta struktūru un noformējumu bieži vien nav viennozīmīgi izgūstama, un teksta segmentēšana teikumos un rindkopās ir apgrūtināta, jo PDF formāts ir veidots satura drukāšanas nevis mašīnlasīšanas vajadzībām.\n",
        "\n",
        "Arī PDF dokumentu apstrādei ir pieejamas dažādas ārējās *Python* bibliotēkas, piemēram, `pypdf`, `PyPDF2`, `PDFMiner`, `PyMuPDF`, `tabula-py`. Demonstrācijas nolūkiem izmantosim `pypdf` (https://pypi.org/project/pypdf/).\n",
        "\n",
        "Plašāk par PDF dokumentu mašīnlasīšanas problemātiku aprakstīts `pypdf` dokumentācijā: https://pypdf.readthedocs.io/en/stable/user/extract-text.html\n",
        "\n",
        "Eksperimentēšanas vērta alternatīva pieeja: konvertēt PDF uz HTML un tālāk strādāt ar HTML dokumentiem. Konvertēšanas funkcionalitāti nodrošina, piemēram, `PDFMiner` (https://pypi.org/project/pdfminer/)."
      ],
      "metadata": {
        "id": "y2b4ioRTQBj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "fNOYOjaAP91t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7fd64c4-0506-43dc-9186-f22e512a5273"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.0.1-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O \"sample_paper.pdf\" https://www.apgads.lu.lv/fileadmin/user_upload/lu_portal/apgads/PDF/Valoda-nozime-forma/VNF-10/vnf_10-16_Nespore_Saulite_Rituma.pdf"
      ],
      "metadata": {
        "id": "bD4oVHMhAxXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55bb41a5-1728-4b64-9100-65d9e7f94a56"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-14 12:06:20--  https://www.apgads.lu.lv/fileadmin/user_upload/lu_portal/apgads/PDF/Valoda-nozime-forma/VNF-10/vnf_10-16_Nespore_Saulite_Rituma.pdf\n",
            "Resolving www.apgads.lu.lv (www.apgads.lu.lv)... 5.179.1.160\n",
            "Connecting to www.apgads.lu.lv (www.apgads.lu.lv)|5.179.1.160|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 920996 (899K) [application/pdf]\n",
            "Saving to: ‘sample_paper.pdf’\n",
            "\n",
            "sample_paper.pdf    100%[===================>] 899.41K  1.10MB/s    in 0.8s    \n",
            "\n",
            "2024-02-14 12:06:22 (1.10 MB/s) - ‘sample_paper.pdf’ saved [920996/920996]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader\n",
        "\n",
        "\n",
        "def pdf_to_txt(pdf_file, txt_file):\n",
        "    input_file = open(pdf_file, \"rb\")\n",
        "    output_file = open(txt_file, \"w\", encoding=\"utf-8\")\n",
        "\n",
        "    reader = PdfReader(input_file)\n",
        "    text = \"\"\n",
        "\n",
        "    # Nolasa dokumentu pa vienai lapai.\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text() + \"\\n\"\n",
        "\n",
        "    output_file.write(normalize_white_spaces(text))\n",
        "    output_file.close()\n",
        "\n",
        "\n",
        "pdf_to_txt(\"sample_paper.pdf\", \"sample_paper.txt\")"
      ],
      "metadata": {
        "id": "YrxiI6npQSbM"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Papētot iegūto rezultātu (`sample_paper.txt`), redzams, ka ar tik vienkāršiem soļiem nepietiek, lai no PDF dokumenta izgūtu kvalitatīvu tekstu.\n",
        "\n",
        "Izteiktākā problēma ir tā, ka izgūtajā tekstā ir saglabāts teksta dalījums rindās un lappusēs tā, kā tas drukas vajadzībām ir izkārtots PDF dokumentā, bet mums ir nepieciešams teksts, kas būtu strukturēts atbilstoši teikumu un rindkopu robežām, nevis dokumenta vizuālajam noformējumam.\n",
        "\n",
        "Lai iegūtu vēlamo rezultātu (t.i., tuvinātos tam), ir jāveic papildu soļi teksta noformējuma analīzē un atbilstošā pēcapstrādē."
      ],
      "metadata": {
        "id": "pbJPfX0hgDmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_lines(text):\n",
        "    # Ja rinda beidzas ar burtu un defisi, pieņemam, ka tas ir vārda pārnesums jaunā rindā.\n",
        "    text = re.sub(r\"(?<=[a-zāčēģīķļņšūž])[--]\\n(?=[a-zāčēģīķļņšūž])\", \"\", text)\n",
        "\n",
        "    # Ja rinda sākas ar mazo burtu, pieņemam, ka teikums turpinās.\n",
        "    text = re.sub(r\"(\\n)+(?=[a-zāčēģīķļņšūž])\", \" \", text) # FIXME: \\p{Ll}\n",
        "\n",
        "    return text\n",
        "\n",
        "def pdf_to_txt_2(pdf_file, txt_file):\n",
        "    input_file = open(pdf_file, \"rb\")\n",
        "    output_file = open(txt_file, \"w\", encoding=\"utf-8\")\n",
        "\n",
        "    reader = PdfReader(input_file)\n",
        "    text = \"\"\n",
        "\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text() + \"\\n\"\n",
        "\n",
        "    text = merge_lines(normalize_white_spaces(text))\n",
        "\n",
        "    output_file.write(text)\n",
        "    output_file.close()\n",
        "\n",
        "\n",
        "pdf_to_txt_2(\"sample_paper.pdf\", \"sample_paper_2.txt\")"
      ],
      "metadata": {
        "id": "1kTb92qOCe_w"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VERT-to-Text\n",
        "\n",
        "Dažkārt nākas saskarties ar failu formātiem, kas nav plaši izplatīti vai tiek izmantoti pamatā tikai valodu tehnoloģiju jomā, un to apstrādei nav pieejamas jau gatavas bibliotēkas, vai arī pastāv vairāki varianti, kā attiecīgais datu formāts var tikt realizēts vai interpretēts.\n",
        "\n",
        "Daži piemēri: CoNLL, VERT, TSV3 - specifiski *tab-separated* failu formāti, kas tiek izmantoti valodu tehnoloģiju jomā. Šādos gadījumos nepieciešams analizēt faila struktūru un attiecīgi iegūt un pārveidot tikai nepieciešamo informāciju.\n",
        "\n",
        "Demonstrācijā aplūkosim VERT/VRT formātu, kura dažādus atvasinājumus izmanto teksta korpusu platformas [SketchEngine](https://www.sketchengine.eu/my_keywords/vertical/), NoSketchEngine, [Korp](https://www.kielipankki.fi/development/korp/corpus-input-format/) u.c. Šis formāts tiek izmantots arī latviešu valodas korpusu platformā [Korpuss.lv](https://korpuss.lv/), kas izmanto NoSketchEngine.\n",
        "\n",
        "Lai no VERT formāta iegūtu vienkāršu, saistītu tekstu ir nepieciešams ievērot teksta segmentēšanu teikumos un teikumu segmentēšanu tekstvienībās atbilstoši VERT formātā lietotajam strukturālajam marķējumam.\n",
        "\n",
        "Demonstrācijai izmantosim Raiņa korpusu, kas atrodams CLARIN-LV repozitorijā: http://hdl.handle.net/20.500.12574/41"
      ],
      "metadata": {
        "id": "ayvqvSpIDB_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O \"sample_corpus.vert\" https://repository.clarin.lv/repository/xmlui/bitstream/handle/20.500.12574/41/rainis_v20180716.vert"
      ],
      "metadata": {
        "id": "9CR8SGBtICnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73090a1e-04d8-4813-c55e-feb4835dc34b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-15 10:15:43--  https://repository.clarin.lv/repository/xmlui/bitstream/handle/20.500.12574/41/rainis_v20180716.vert\n",
            "Resolving repository.clarin.lv (repository.clarin.lv)... 92.240.80.87\n",
            "Connecting to repository.clarin.lv (repository.clarin.lv)|92.240.80.87|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 200\n",
            "Length: 47156135 (45M) [application/octet-stream]\n",
            "Saving to: ‘sample_corpus.vert’\n",
            "\n",
            "sample_corpus.vert  100%[===================>]  44.97M  14.0MB/s    in 3.5s    \n",
            "\n",
            "2024-02-15 10:15:48 (12.8 MB/s) - ‘sample_corpus.vert’ saved [47156135/47156135]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vert_to_txt(vert_file, txt_file):\n",
        "    input_file = open(vert_file, \"r\", encoding=\"utf-8\")\n",
        "    output_file = open(txt_file, \"w\", encoding=\"utf-8\")\n",
        "    text = \"\"\n",
        "\n",
        "    # Nolasa VERT failu pa vienai rindiņai un rekonstruē oriģinālos teikumus un to dalījumu rindkopās.\n",
        "    while True:\n",
        "        line = input_file.readline()\n",
        "\n",
        "        if not line: break\n",
        "\n",
        "        if line == \"\\n\":\n",
        "            if text != \"\":\n",
        "                output_file.write(text + \"\\n\")\n",
        "            text = \"\"\n",
        "\n",
        "        # Ja tiek nolasīts marķējuma simbols, veicam attiecīgās struktūras apstrādi.\n",
        "        elif line[0] == \"<\" and line[1] != \"\\t\":\n",
        "\n",
        "            # </doc>, </p>, </s> - apzīmē dokumenta, paragrāfa, teikuma beigas.\n",
        "            # Līdz šim atmiņā rekonstruēto teikumu ieraksta izvadfailā un sāk nākamā teikuma rekonstruēšanu.\n",
        "            if line == \"</doc>\\n\":\n",
        "                if text[:-1] == \" \":\n",
        "                    text = text[:-1]\n",
        "                output_file.write(text + \"\\n\\n\")\n",
        "                text = \"\"\n",
        "            elif line == \"</p>\\n\":\n",
        "                if text[:-1] == \" \":\n",
        "                    text = text[:-1]\n",
        "                output_file.write(text + \"\\n\")\n",
        "                text = \"\"\n",
        "            elif line == \"</s>\\n\":\n",
        "                if text[:-1] == \" \":\n",
        "                    text = text[:-1]\n",
        "                output_file.write(text)\n",
        "                text = \"\"\n",
        "\n",
        "            # <g/> - \"glue tag\" norāda, ka starp tekstvienībām nav jabūt atstarpei.\n",
        "            # Piemērs: vārds un tam sekojoša interpunkcijas zīme.\n",
        "            elif line == \"<g />\\n\" and len(text) > 1:\n",
        "                if text[-1] == \" \":\n",
        "                    text = text[:-1]\n",
        "\n",
        "            # Ignorē atverošos <doc>, <p>, <s> marķējumus.\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "        # Ja faila tekošā rindiņa nesatur marķējuma simbolu, tad tā satur tekstvienību - pievienojam to izvadam.\n",
        "        # Atbilstoši VERT struktūrai, katras šādas rindiņas pirmais elements (lauks) satur tekstvienību tās oriģinālajā formā.\n",
        "        else:\n",
        "            text = text + line.split(\"\\t\")[0] + \" \"\n",
        "\n",
        "\n",
        "vert_to_txt(\"sample_corpus.vert\", \"sample_corpus.txt\")"
      ],
      "metadata": {
        "id": "uYnTQQW6FM7O"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}