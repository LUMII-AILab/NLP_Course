{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Vibe coding\n",
        "Demonstrate LLM tool calling using the openai package. Define a function named flip_coin() that simulates a coin flip and returns either \"heads\" or \"tails\". It should use the OpenAI client to connect to an OpenAI-compatible endpoint hosted at http://gauja.ailab.lv:30054/v1 with the model name openai/gpt-oss-120b. The script must implement a complete tool-calling loop: send messages to the model, print all messages sent and received (including tool calls and responses), and whenever the model requests a tool call, execute the corresponding function locally and send the result back to the model. Continue this process until the model’s final response contains no more tool calls. Demonstrate the full interaction by asking the model: “Flip a coin to decide if I should go to school today.” The program should keep responding to tool call messages until the model produces a normal text response."
      ],
      "metadata": {
        "id": "7GchCqBzu7v_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec806fc6"
      },
      "source": [
        "# Task\n",
        "Demonstrate LLM tool calling using the openai package. Define a function named `flip_coin()` that simulates a coin flip and returns either \"heads\" or \"tails\". It should use the OpenAI client to connect to an OpenAI-compatible endpoint hosted at http://gauja.ailab.lv:30054/v1 with the model name openai/gpt-oss-120b. The script must implement a complete tool-calling loop: send messages to the model, print all messages sent and received (including tool calls and responses), and whenever the model requests a tool call, execute the corresponding function locally and send the result back to the model. Continue this process until the model’s final response contains no more tool calls. Demonstrate the full interaction by asking the model: “Flip a coin to decide if I should go to school today.” The program should keep responding to tool call messages until the model produces a normal text response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3681b1d5"
      },
      "source": [
        "## Install dependencies\n",
        "\n",
        "### Subtask:\n",
        "Install the `openai` package.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27761425"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to install the `openai` package. I will use pip to install it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62139307"
      },
      "source": [
        "%pip install openai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e0068a6"
      },
      "source": [
        "## Define tool function\n",
        "\n",
        "### Subtask:\n",
        "Define the `flip_coin()` function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bdfc9ba"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the `flip_coin` function as requested in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91318b1c"
      },
      "source": [
        "import random\n",
        "\n",
        "def flip_coin():\n",
        "  \"\"\"Simulates a coin flip and returns 'heads' or 'tails'.\"\"\"\n",
        "  return random.choice([\"heads\", \"tails\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83fa9a83"
      },
      "source": [
        "## Set up openai client\n",
        "\n",
        "### Subtask:\n",
        "Set up the OpenAI client with the specified endpoint and model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9814c471"
      },
      "source": [
        "**Reasoning**:\n",
        "Instantiate the OpenAI client with the specified base URL.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc852789"
      },
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(base_url=\"http://gauja.ailab.lv:30054/v1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7f6559b"
      },
      "source": [
        "**Reasoning**:\n",
        "The error indicates that an API key is required even when using a custom base URL. Provide a dummy API key to satisfy the client's requirement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pl_ZmzZ9gBV"
      },
      "source": [
        "client = OpenAI(base_url=\"http://gauja.ailab.lv:30054/v1\", api_key=\"dummy_key\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ece2d6b"
      },
      "source": [
        "## Implement tool calling loop\n",
        "\n",
        "### Subtask:\n",
        "Implement the loop to send messages, handle tool calls, and execute functions locally.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4f17cf1"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the tool calling loop as described in the instructions, including sending messages, handling tool calls, executing functions, and updating the message history.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7fd9adf",
        "outputId": "69db72d8-f5bf-4549-f3a8-eb48f2a15e46"
      },
      "source": [
        "messages = []\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"flip_coin\",\n",
        "            \"description\": \"Simulates a coin flip and returns 'heads' or 'tails'.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {},\n",
        "                \"required\": [],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "messages.append({\"role\": \"user\", \"content\": \"Flip a coin to decide if I should go to school today.\"})\n",
        "\n",
        "while True:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"openai/gpt-oss-120b\",\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",\n",
        "    )\n",
        "    print(\"Model Response:\", response)\n",
        "\n",
        "    response_message = response.choices[0].message\n",
        "    messages.append(response_message)\n",
        "\n",
        "    if response_message.tool_calls:\n",
        "        available_tools = {\"flip_coin\": flip_coin}\n",
        "        for tool_call in response_message.tool_calls:\n",
        "            function_name = tool_call.function.name\n",
        "            function_to_call = available_tools[function_name]\n",
        "            function_args = {} # No arguments for flip_coin\n",
        "            function_response = function_to_call(**function_args)\n",
        "            messages.append(\n",
        "                {\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"role\": \"tool\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response,\n",
        "                }\n",
        "            )\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Final Conversation History:\", messages)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Response: ChatCompletion(id='chatcmpl-4dc9e2c6ee8044f0b8fbaa4d48ecb2e8', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='chatcmpl-tool-d0d79ea847bb4a7da7d41d3523275a72', function=Function(arguments='{}', name='flip_coin'), type='function')], reasoning_content='The user wants to flip a coin to decide if they should go to school today. Need to invoke flip_coin function. Then respond with result.'), stop_reason=200012, token_ids=None)], created=1761674154, model='openai/gpt-oss-120b', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=49, prompt_tokens=134, total_tokens=183, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None, prompt_token_ids=None, kv_transfer_params=None)\n",
            "Model Response: ChatCompletion(id='chatcmpl-e10631c44b1b49b5beed349e150df6c7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The coin landed **heads** – that’s the signal to go to school today! Good luck, and have a great day!', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[], reasoning_content='User wants a coin flip result. We have result \"heads\". Need to answer accordingly: coin shows heads, so advise. Possibly interpret heads as go to school. Provide suggestion.'), stop_reason=None, token_ids=None)], created=1761674155, model='openai/gpt-oss-120b', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=72, prompt_tokens=158, total_tokens=230, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None, prompt_token_ids=None, kv_transfer_params=None)\n",
            "Final Conversation History: [{'role': 'user', 'content': 'Flip a coin to decide if I should go to school today.'}, ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='chatcmpl-tool-d0d79ea847bb4a7da7d41d3523275a72', function=Function(arguments='{}', name='flip_coin'), type='function')], reasoning_content='The user wants to flip a coin to decide if they should go to school today. Need to invoke flip_coin function. Then respond with result.'), {'tool_call_id': 'chatcmpl-tool-d0d79ea847bb4a7da7d41d3523275a72', 'role': 'tool', 'name': 'flip_coin', 'content': 'heads'}, ChatCompletionMessage(content='The coin landed **heads** – that’s the signal to go to school today! Good luck, and have a great day!', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[], reasoning_content='User wants a coin flip result. We have result \"heads\". Need to answer accordingly: coin shows heads, so advise. Possibly interpret heads as go to school. Provide suggestion.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "357ae75b"
      },
      "source": [
        "## Demonstrate interaction\n",
        "\n",
        "### Subtask:\n",
        "Demonstrate the full interaction by asking the model: “Flip a coin to decide if I should go to school today.”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1987f7ce"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The `openai` package was successfully installed and configured to connect to the specified OpenAI-compatible endpoint.\n",
        "*   A `flip_coin()` function was defined to simulate a coin flip, returning either \"heads\" or \"tails\".\n",
        "*   A tool-calling loop was successfully implemented, allowing the LLM to request the execution of the `flip_coin` function.\n",
        "*   The model correctly identified the user's request to flip a coin and initiated the tool call.\n",
        "*   The output of the local `flip_coin` function was sent back to the model, which then used the result to provide a final response.\n",
        "*   The full conversation history, including user messages, model responses (with and without tool calls), and tool responses, was successfully captured and displayed, demonstrating the complete tool-calling workflow.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   This implementation provides a clear template for integrating custom functions as tools for LLMs, enabling the model to interact with external processes or data.\n",
        "*   Future steps could involve defining more complex tools with parameters and implementing error handling for tool execution failures.\n"
      ]
    }
  ]
}