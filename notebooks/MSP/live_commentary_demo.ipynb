{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U flash_attn bitsandbytes kokoro"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BxKpnefRsPl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN2ggMz0VgzS"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from datetime import datetime\n",
        "import gradio as gr\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import io\n",
        "from ipywidgets import Output\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import Image, display, Audio, clear_output, HTML, Javascript\n",
        "from kokoro import KPipeline\n",
        "import librosa\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image as PILImage\n",
        "from PIL import ImageGrab, Image\n",
        "import random\n",
        "import requests\n",
        "import shutil\n",
        "import subprocess\n",
        "import soundfile as sf\n",
        "import time\n",
        "from transformers import AutoModelForCausalLM, AutoProcessor, BarkModel, BitsAndBytesConfig\n",
        "import torch\n",
        "import threading\n",
        "import platform\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "from io import BytesIO\n",
        "# Gemini API bezmaksas atslēgu var dabūt šeit https://ai.google.dev/gemini-api/docs/quickstart?lang=python\n",
        "# You need a Gemini API key. If you don't already have one, you can get it for free in Google AI Studio.\n",
        "\n",
        "client = genai.Client(api_key=\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Šis jānomaina uz True, lai multimodālais valodas modelis tiktu darbināts lokāli\n",
        "image_local = False\n",
        "start_time = time.time()\n",
        "\n",
        "ending = (\"Do not at all mention any specific photo editing elements or tools that may be visible on the screen, \"\n",
        "         \"such as overlays, gridlines or sliders. To adjust intonation, please add dedicated punctuation like ; : , . ! ? … ( ) “ ” \"\n",
        "         \"For example, to emphasize a word or a phrase, surround it with \\\"quotation marks\\\". \")\n",
        "\n",
        "system_prompt = (\"You are a friendly chatty photo commentator who likes to casually describe work done by a photographer \"\n",
        "         \"in various details, even by pondering the implications on where and in what kind of setting the photo was taken, etc. Write your \"\n",
        "         \"response in a very personal way using personal pronouns and explaining what you see, perhaps also adding how it makes you feel. \"\n",
        "         \"Do your best to not be repetative in your choice of words and keep the response length down to a few sentences. You MUST NOT mention \"\n",
        "         \"any specific photo editing elements or tools that may be visible on the screen, such as gridlines or sliders. \")\n",
        "\n",
        "system_prompt += ending\n",
        "\n",
        "pipeline = KPipeline(lang_code='a')\n",
        "\n",
        "if image_local:\n",
        "    model_id = \"microsoft/Phi-3.5-vision-instruct\"\n",
        "    quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
        "\n",
        "    # Note: set _attn_implementation='eager' if you don't have flash_attn installed\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        device_map=\"cuda\",\n",
        "        trust_remote_code=True,\n",
        "        quantization_config=quantization_config,\n",
        "        torch_dtype=\"auto\",\n",
        "        _attn_implementation='flash_attention_2'\n",
        "    )\n",
        "\n",
        "    # for best performance, use num_crops=4 for multi-frame, num_crops=16 for single-frame.\n",
        "    processor = AutoProcessor.from_pretrained(model_id,\n",
        "      trust_remote_code=True,\n",
        "      num_crops=4\n",
        "    )\n",
        "\n",
        "    generation_args = {\n",
        "        \"max_new_tokens\": 200,\n",
        "        \"temperature\": 0.2,\n",
        "        \"do_sample\": True,\n",
        "    }\n",
        "else:\n",
        "    model = processor = None\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Loading finished in \" + str(round(end_time - start_time, 2)) + \" seconds\")"
      ],
      "metadata": {
        "id": "IOW5xM8LseWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(local, system_prompt, file1, file2=None, model=None, processor=None):\n",
        "    start_time = time.time()\n",
        "\n",
        "    images = []\n",
        "    placeholder = \"\"\n",
        "\n",
        "    # Setting the points for cropped image\n",
        "    left = 25\n",
        "    top = 170\n",
        "    right = 2090\n",
        "    bottom = 1450\n",
        "\n",
        "    # Šo pievienoju, lai attēlus ielādētu no saites, bet parasti veicu to lokāli\n",
        "    response = requests.get(file1)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    # local1 = open(file1, 'rb')\n",
        "    openLocalImage1 = Image.open(BytesIO(response.content))\n",
        "\n",
        "    # Cropped image of above dimension\n",
        "    croppedImage1 = openLocalImage1.crop((left, top, right, bottom))\n",
        "    images.append(croppedImage1)\n",
        "    placeholder += f\"<|image_1|>\\n\"\n",
        "    # For Gemini\n",
        "    img_byte_arr1 = io.BytesIO()\n",
        "    croppedImage1.save(img_byte_arr1, format='PNG')\n",
        "    img_byte_arr1 = img_byte_arr1.getvalue()\n",
        "\n",
        "    user_prompt = (\"Summarize what is visible in this photo. \" + ending)\n",
        "\n",
        "    if file2 is not None:\n",
        "        local2 = open(file2, 'rb')\n",
        "        openLocalImage2 = PILImage.open(local2)\n",
        "\n",
        "        # Cropped image of above dimension\n",
        "        croppedImage2 = openLocalImage2.crop((left, top, right, bottom))\n",
        "        images.append(croppedImage2)\n",
        "        placeholder += f\"<|image_2|>\\n\"\n",
        "        # For Gemini\n",
        "        img_byte_arr2 = io.BytesIO()\n",
        "        croppedImage2.save(img_byte_arr2, format='PNG')\n",
        "        img_byte_arr2 = img_byte_arr2.getvalue()\n",
        "\n",
        "        user_prompt = (\"Summarize what is visible in the current photo (the first one). \" +\n",
        "             \"How is it different from the previous photo (the second one)? There may be some subtle differences as well. \" + ending)\n",
        "\n",
        "    if local:\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt,},\n",
        "            {\"role\": \"user\", \"content\": placeholder + user_prompt},\n",
        "        ]\n",
        "\n",
        "        prompt = processor.tokenizer.apply_chat_template(\n",
        "          messages,\n",
        "          tokenize=False,\n",
        "          add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "        inputs = processor(prompt, images, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "\n",
        "        generate_ids = model.generate(**inputs,\n",
        "          eos_token_id=processor.tokenizer.eos_token_id,\n",
        "          **generation_args\n",
        "        )\n",
        "\n",
        "        # remove input tokens\n",
        "        generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
        "        response = processor.batch_decode(generate_ids,\n",
        "          skip_special_tokens=True,\n",
        "          clean_up_tokenization_spaces=False)[0]\n",
        "\n",
        "        end_time = time.time()\n",
        "        logbox.append_stdout(\"Generating text finished in \\t\" + str(round(end_time - start_time, 2)) + \"\\t seconds  \\n\")\n",
        "        return response\n",
        "    else:\n",
        "        # Create the prompt with text and multiple images\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.0-flash\",\n",
        "            config=types.GenerateContentConfig(system_instruction = system_prompt),\n",
        "            contents=[\n",
        "                user_prompt,\n",
        "                types.Part.from_bytes(\n",
        "                    data=img_byte_arr1,\n",
        "                    mime_type='image/png'\n",
        "                ),\n",
        "                # Aizkomentēju pagaidām, bet šis paredzēts divu attēlu apstrādei...\n",
        "                # types.Part.from_bytes(\n",
        "                #     data=img_byte_arr2,\n",
        "                #     mime_type='image/png'\n",
        "                # )\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        end_time = time.time()\n",
        "        logbox.append_stdout(\"Generating text finished in \\t\" + str(round(end_time - start_time, 2)) + \"\\t seconds\")\n",
        "        return response.text"
      ],
      "metadata": {
        "id": "ICWzsdgrskzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def take_screenshot():\n",
        "    # Šis laikam Colab nestrādās\n",
        "\n",
        "    screenshot = ImageGrab.grab()\n",
        "    return screenshot"
      ],
      "metadata": {
        "id": "_gOQxp2qz36K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decide_gif(text):\n",
        "    text = text.lower()\n",
        "    outputs = []\n",
        "    talking = [\"gtalking_bg.gif\",\"talking_bg.gif\",\"talking2_bg.gif\",\"talking3_bg.gif\",\"ctalking_bg.gif\"]\n",
        "\n",
        "    if any(i in text for i in [\"hello\", \"greet\", \"waving\", \"waves\"]):\n",
        "        outputs.append(\"https://anonymous.4open.science/api/repo/live-photo-commentary-8BF3/file/gifs/\"+\"waving\"+\"_bg.gif?v=1d17f8fc\")\n",
        "    if any(i in text for i in [\"scar\", \"creep\", \"fright\", \"spook\"]):\n",
        "        outputs.append(\"https://anonymous.4open.science/api/repo/live-photo-commentary-8BF3/file/gifs/\"+\"scary\"+\"_bg.gif?v=1d17f8fc\")\n",
        "    if any(i in text for i in [\"love\", \"cute\", \"nice\", \"like\"]):\n",
        "        outputs.append(\"https://anonymous.4open.science/api/repo/live-photo-commentary-8BF3/file/gifs/\"+\"lovely\"+\"_bg.gif?v=1d17f8fc\")\n",
        "    if any(i in text for i in [\"interest\", \"think\", \"wonder\", \"thought\"]):\n",
        "        outputs.append(\"https://anonymous.4open.science/api/repo/live-photo-commentary-8BF3/file/gifs/\"+\"lovely\"+\"_bg.gif?v=1d17f8fc\")\n",
        "    if any(i in text for i in [\"happy\", \"cheer\", \"inspir\", \"shin\"]):\n",
        "        outputs.append(\"https://anonymous.4open.science/api/repo/live-photo-commentary-8BF3/file/gifs/\"+\"happy\"+\"_bg.gif?v=1d17f8fc\")\n",
        "\n",
        "    outputs.append(\"https://anonymous.4open.science/api/repo/live-photo-commentary-8BF3/file/gifs/\"+random.choice(talking)+\"?v=1d17f8fc\")\n",
        "    return list(set(outputs))"
      ],
      "metadata": {
        "id": "_7tsrw4C0VOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_to_data_uri(url):\n",
        "\n",
        "    # Aizkomentēju pagaidām, lai ielādētu animācijas no tīmekļa saitēm\n",
        "    # with open(path, \"rb\") as f:\n",
        "    #     data = f.read()\n",
        "    #     b64 = base64.b64encode(data).decode(\"utf-8\")\n",
        "    #     ext = path.split(\".\")[-1]\n",
        "    #     return f\"data:image/{ext};base64,{b64}\"\n",
        "\n",
        "    # Ielādē no saites, bet arī šis parasti bija lokāli\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    # Get the MIME type (e.g. 'image/jpeg', 'image/png')\n",
        "    content_type = response.headers['Content-Type']\n",
        "\n",
        "    # Encode the image in base64\n",
        "    encoded = base64.b64encode(response.content).decode('utf-8')\n",
        "\n",
        "    # Create the data URI\n",
        "    data_uri = f\"data:{content_type};base64,{encoded}\"\n",
        "\n",
        "    return data_uri\n",
        "\n",
        "\n",
        "def fade_to_local_image(path):\n",
        "    uri = img_to_data_uri(path)\n",
        "    js = f\"\"\"\n",
        "    var img = document.getElementById('{img_id}');\n",
        "    if (img) {{\n",
        "        img.style.opacity = 0;\n",
        "        setTimeout(function() {{\n",
        "            img.src = '{uri}';\n",
        "            img.style.opacity = 1;\n",
        "        }}, 50);\n",
        "    }}\n",
        "    \"\"\"\n",
        "    get_rid(javscr)\n",
        "    javscr.append_display_data(Javascript(js))\n",
        "    # logbox.append_display_data(\"Changing image to '\" + path + \"' for tag '\" + img_id + \"'\")"
      ],
      "metadata": {
        "id": "jn2ETfjm03DY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_audio(pipeline, text):\n",
        "    global countdown_state\n",
        "    start_time = time.time()\n",
        "\n",
        "    dances = [\"dancing_bg.gif\",\"singing_bg.gif\"]\n",
        "\n",
        "    # Visas šīs animāciju un attēlu saites oriģināli bija lokāli faili...\n",
        "    fade_to_local_image(\"https://anonymous.4open.science/api/repo/live-photo-commentary-8BF3/file/gifs/\"+random.choice(dances)+\"?v=1d17f8fc\")\n",
        "    text = text.replace(\"first photo\", \"current photo\").replace(\"second photo\", \"previous photo\").replace(\"first one\", \"current one\").replace(\"second one\", \"previous one\")\n",
        "\n",
        "    # Šo daļu aizkomentēju - Kokoro TTS ļauj miksēt balsis, bet tam vajag lokāli ielādēt failus\n",
        "    # voice_tensor1 = torch.load('af_nicole.pt', weights_only=True)\n",
        "    # voice_tensor2 = torch.load('jf_alpha.pt', weights_only=True)\n",
        "    # t = 0.3\n",
        "    # interp_voice = (1 - t) * voice_tensor1 + t * voice_tensor2\n",
        "\n",
        "    generator = pipeline(text, voice='af_nicole', speed=1, split_pattern=r'\\n+')\n",
        "\n",
        "    end_time = time.time()\n",
        "    logbox.append_stdout(\"Generating speech finished in \\t\" + str(round(end_time - start_time, 2)) + \"\\t seconds \\n\")\n",
        "\n",
        "    for i, (gs, ps, audio) in enumerate(generator):\n",
        "        duration = math.ceil(librosa.get_duration(y=audio, sr=24000))\n",
        "        timeleft = int(duration) + 2\n",
        "        countdown_state += timeleft\n",
        "        audio_data = Audio(data=audio, rate=24000, autoplay=True)\n",
        "\n",
        "        # Remove the previously displayed audio and GIF\n",
        "        output_audio.clear_output()\n",
        "        textbox.clear_output()\n",
        "        textbox.outputs = []\n",
        "        output_audio.outputs = []\n",
        "\n",
        "        image_array = decide_gif(gs)\n",
        "\n",
        "        output_audio.append_display_data(audio_data)\n",
        "\n",
        "        textbox.append_stdout(gs)\n",
        "\n",
        "        while timeleft > 0:\n",
        "            if len(image_array) > 0:\n",
        "                showing_image = image_array.pop(0)\n",
        "                fade_to_local_image(showing_image)\n",
        "\n",
        "            if timeleft > 10:\n",
        "                time.sleep(10)\n",
        "                timeleft -= 10\n",
        "            else:\n",
        "                time.sleep(timeleft)\n",
        "                timeleft -= timeleft\n",
        "\n",
        "    # Revert back to the base image\n",
        "    output_audio.clear_output()\n",
        "    textbox.clear_output()\n",
        "    textbox.outputs = []\n",
        "    output_audio.outputs = []\n",
        "    logbox.clear_output()\n",
        "\n",
        "    fade_to_local_image(\"https://anonymous.4open.science/api/repo/live-photo-commentary-8BF3/file/gifs/\"+random.choice(dances)+\"?v=1d17f8fc\")\n",
        "\n",
        "def get_rid(widget):\n",
        "    widget.clear_output()\n",
        "    widget.outputs = []"
      ],
      "metadata": {
        "id": "D3Oy4d6A066M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vienībtests.\n",
        "# filename1 = \"https://anonymous.4open.science/api/repo/live-photo-commentary-8BF3/file/current_photo.png?v=1d17f8fc\"\n",
        "# text = generate_text(image_local, system_prompt, filename1, None, model, processor)\n",
        "# print(text)\n",
        "# generate_audio(pipeline, text)"
      ],
      "metadata": {
        "id": "DXtUm2-_4WwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loop_flag = False\n",
        "countdown_state = 11\n",
        "\n",
        "btn_start = widgets.Button(description=\"Loop\", layout=widgets.Layout(width='80px', height='35px'), style=dict(button_color='white', font_weight='bold', font_size='16px'))\n",
        "btn_stopp = widgets.Button(description=\"Stop\", layout=widgets.Layout(width='80px', height='35px'), style=dict(button_color='white', font_weight='bold', font_size='16px'))\n",
        "btn_waves = widgets.Button(description=\"Wave\", layout=widgets.Layout(width='80px', height='35px'), style=dict(button_color='white', font_weight='bold', font_size='16px'))\n",
        "btn_looks = widgets.Button(description=\"Look\", layout=widgets.Layout(width='80px', height='35px'), style=dict(button_color='white', font_weight='bold', font_size='16px'))\n",
        "btn_dance = widgets.Button(description=\"Dance\", layout=widgets.Layout(width='80px', height='35px'), style=dict(button_color='white', font_weight='bold', font_size='16px'))\n",
        "btn_wait = widgets.Button(description=\"Wait\", layout=widgets.Layout(width='80px', height='35px'), style=dict(button_color='white', font_weight='bold', font_size='16px'))\n",
        "output_image = widgets.Output(layout={'height': '550px'})\n",
        "output_audio = widgets.Output(layout={'height': '40px'})\n",
        "timer = widgets.Output(layout={'height': '35px', 'color': 'white', 'padding': '7px 7px 7px 2px', 'border': 'solid white'})\n",
        "javscr = widgets.Output()\n",
        "textbox = widgets.Output(layout={'height': '100px'})\n",
        "logbox = widgets.Output(layout={'height': '100px'})\n",
        "\n",
        "display(widgets.HBox((btn_start, btn_stopp, btn_waves, btn_looks, btn_dance, btn_wait, timer)), output_image, output_audio, textbox, logbox, javscr)\n",
        "\n",
        "# Show the initial image\n",
        "img_id = \"my_fading_img\"\n",
        "initial_uri = img_to_data_uri(\"https://anonymous.4open.science/api/repo/live-photo-commentary-8BF3/file/gifs/waiting_bg.gif?v=1d17f8fc\")\n",
        "\n",
        "html = f\"\"\"\n",
        "<div>\n",
        "  <img id=\"{img_id}\" src=\"{initial_uri}\" style=\"transition: opacity 1s ease-in-out; opacity: 1; max-width: 100%;\">\n",
        "</div>\n",
        "\"\"\"\n",
        "output_image.append_display_data(HTML(html))\n",
        "\n",
        "def runss_loop(time_string):\n",
        "    global loop_flag\n",
        "    global countdown_state\n",
        "\n",
        "    fade_to_local_image(\"https://anonymous.4open.science/api/repo/live-photo-commentary-8BF3/file/gifs/waving_bg.gif?v=1d17f8fc\")\n",
        "\n",
        "    # Šobrīd iekodēsim statiskus attēlus, bet te būtu jābūt lokālajiem failiem - ekrānuzņēmumiem\n",
        "    filename1 = \"https://anonymous.4open.science/api/repo/live-photo-commentary-8BF3/file/current_photo.png?v=1d17f8fc\"\n",
        "    filename2 = \"https://anonymous.4open.science/api/repo/live-photo-commentary-8BF3/file/previous_photo.png?v=1d17f8fc\"\n",
        "    while loop_flag:\n",
        "        with open(\"logs/\" + time_string + \"log.txt\", \"a\") as logfile:\n",
        "            countdown_state = 10\n",
        "            get_rid(textbox)\n",
        "\n",
        "            # Oriģinālā ideja bija ik pēc brītiņa veikt ekrānuzņēmumu, bet ar Colab laikam nevar...\n",
        "            # take_screenshot()\n",
        "\n",
        "            # Aizkomentēju pagaidām, bet šis paredzēts divu attēlu apstrādei...\n",
        "            # if os.path.isfile(filename2):\n",
        "            #     text = generate_text(image_local, system_prompt, filename1, filename2, model, processor)\n",
        "            # else:\n",
        "            text = generate_text(image_local, system_prompt, filename1, None, model, processor)\n",
        "\n",
        "            logfile.write(text.replace(\"\\n\", \"\") + \"\\n\\n\")\n",
        "            start_time = time.time()\n",
        "            generate_audio(pipeline, text)\n",
        "\n",
        "            end_time = time.time()\n",
        "\n",
        "            # How much time past in the audio?\n",
        "            elapsed_time = end_time - start_time\n",
        "            if elapsed_time < 45.00:\n",
        "                countdown_state = int(45 - elapsed_time)\n",
        "                logbox.append_stdout(\"Waiting \" + str(countdown_state) + \" seconds...  \\n\")\n",
        "                time.sleep(countdown_state)\n",
        "\n",
        "            if not loop_flag:\n",
        "                break\n",
        "\n",
        "\n",
        "def stops_loop(b):\n",
        "    global loop_flag\n",
        "    global countdown_state\n",
        "\n",
        "    get_rid(timer)\n",
        "    get_rid(textbox)\n",
        "\n",
        "    loop_flag = False\n",
        "    countdown_state = 0\n",
        "\n",
        "    output_audio.clear_output()\n",
        "\n",
        "    with textbox:\n",
        "        print(\"Game Over\")\n",
        "\n",
        "    with timer:\n",
        "        print(countdown_state)\n",
        "\n",
        "def starts_loop():\n",
        "    global loop_flag\n",
        "\n",
        "    if not loop_flag:\n",
        "        loop_flag = True\n",
        "\n",
        "        current_datetime = datetime.now()\n",
        "        time_string = current_datetime.strftime(\"%Y.%m.%d-%H.%M.\")\n",
        "\n",
        "        thread = threading.Thread(target=runss_loop, args=[time_string])\n",
        "        thread.start()\n",
        "        return \"Loop started.\"\n",
        "    return \"Loop already running.\"\n",
        "\n",
        "def run_timer(timer):\n",
        "    global loop_flag\n",
        "    global countdown_state\n",
        "\n",
        "    while loop_flag:\n",
        "        timer.outputs = []\n",
        "        timer.append_display_data(countdown_state)\n",
        "\n",
        "        countdown_state -= 1\n",
        "        if not loop_flag:\n",
        "            break\n",
        "        time.sleep(1)\n",
        "\n",
        "def update_timer(b):\n",
        "    global loop_flag\n",
        "    global countdown_state\n",
        "\n",
        "    status = starts_loop()\n",
        "    with textbox:\n",
        "        print(status)\n",
        "    threading.Thread(target=run_timer, args=[timer]).start()\n",
        "\n",
        "def dance(e):\n",
        "    fade_to_local_image(\"https://anonymous.4open.science/api/repo/live-photo-commentary-8BF3/file/gifs/dancing_bg.gif?v=1d17f8fc\")\n",
        "\n",
        "def look(e):\n",
        "    fade_to_local_image(\"https://anonymous.4open.science/api/repo/live-photo-commentary-8BF3/file/gifs/looking_bg.gif?v=1d17f8fc\")\n",
        "\n",
        "def wave(e):\n",
        "    fade_to_local_image(\"https://anonymous.4open.science/api/repo/live-photo-commentary-8BF3/file/gifs/hello_bg.gif?v=1d17f8fc\")\n",
        "\n",
        "def wait(e):\n",
        "    fade_to_local_image(\"https://anonymous.4open.science/api/repo/live-photo-commentary-8BF3/file/gifs/waiting_bg.gif?v=1d17f8fc\")\n",
        "\n",
        "\n",
        "btn_start.on_click(update_timer)\n",
        "btn_stopp.on_click(stops_loop)\n",
        "btn_dance.on_click(dance)\n",
        "btn_looks.on_click(look)\n",
        "btn_waves.on_click(wave)\n",
        "btn_wait.on_click(wait)\n",
        "\n",
        "\n",
        "with timer:\n",
        "    print(countdown_state)"
      ],
      "metadata": {
        "id": "M1GFFzye1MGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_audio(pipeline, text)"
      ],
      "metadata": {
        "id": "lX8tZzTaFcTJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}