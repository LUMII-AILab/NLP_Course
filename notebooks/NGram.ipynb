{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/LUMII-AILab/NLP_Course/blob/main/notebooks/NGram.ipynb\" target=\"_new\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
      ],
      "metadata": {
        "id": "lVtA3m48_oBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python: NLTK and Counter"
      ],
      "metadata": {
        "id": "zbom9vBdWRSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "fk0ZMMlfWhRe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab') # A pre-trained tokenizer"
      ],
      "metadata": {
        "id": "1IwRgDv9fITC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_ngrams(text, n):\n",
        "  tokens = nltk.word_tokenize(text.lower())  # Simple normalization and tokenization\n",
        "\n",
        "  ngram_counts = []\n",
        "\n",
        "  for i in range(1, n+1):\n",
        "    ngram_list = list(ngrams(tokens, i))\n",
        "    ngram_counts.append(Counter(ngram_list))\n",
        "\n",
        "  return ngram_counts"
      ],
      "metadata": {
        "id": "hSA0i6MEZh3z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_ngram_counts(ngram_counts, filename):\n",
        "  with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
        "    for i, counts in enumerate(ngram_counts):\n",
        "      file.write(f\"--- {i+1}-grams ---\\n\")\n",
        "      sorted_counts = counts.most_common() # Get a sorted frequency list\n",
        "\n",
        "      for ngram, count in sorted_counts:\n",
        "        if count > 1: # Prune the long tail\n",
        "          file.write(f\"{' '.join(ngram)}: {count}\\n\") # Convert tuple of tokens to a string\n",
        "\n",
        "      file.write(\"\\n\")"
      ],
      "metadata": {
        "id": "iXPIMgBgdb_7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://raw.githubusercontent.com/LUMII-AILab/NLP_Course/refs/heads/main/notebooks/resources/velnini.txt"
      ],
      "metadata": {
        "id": "wU7hEHB2afgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\n",
        "with open(\"velnini.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "  text = file.read()\n",
        "\n",
        "ngram_counts = count_ngrams(text, 3) # Get unigrams, bigrams and trigrams\n",
        "\n",
        "save_ngram_counts(ngram_counts, \"ngram_counts.txt\")"
      ],
      "metadata": {
        "id": "SJBlOz9fatEo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenGrm toolkit"
      ],
      "metadata": {
        "id": "w2neZzt_fO4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NGram library\n",
        "\n",
        "A command-line toolkit for making and manipulating n-gram language models encoded as weighted finite-state transducers (FSTs): https://www.openfst.org/twiki/bin/view/GRM/NGramLibrary\n",
        "\n",
        "Operations for counting, smoothing, pruning, applying, and evaluating models are provided."
      ],
      "metadata": {
        "id": "q6z8pbVFe3md"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Dd1FJbJdb3b"
      },
      "outputs": [],
      "source": [
        "# Install the (Mini)Conda package manager in the Colab environment.\n",
        "# See https://docs.conda.io for more detail.\n",
        "\n",
        "# Download the installation script and make it executable\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "\n",
        "# Install Miniconda (-b: silently, -f: forcefully, -p: path)\n",
        "!./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install NGram via Conda (-c: channel, -y: non-interactive)\n",
        "!conda install -c conda-forge ngram -y"
      ],
      "metadata": {
        "id": "XtVmZNSRdg2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a sample text corpus: a normalized copy of Oscar Wilde's \"Importance of Being Earnest\".\n",
        "!wget https://www.openfst.org/twiki/pub/GRM/NGramQuickTour/earnest.txt"
      ],
      "metadata": {
        "id": "_rE6v1rcETFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a symbol table from the corpus\n",
        "!ngramsymbols earnest.txt earnest.syms\n",
        "\n",
        "# Given the symbol table, compile the corpus into an FST\n",
        "!farcompilestrings --fst_type=compact --symbols=earnest.syms --keep_symbols earnest.txt earnest.far"
      ],
      "metadata": {
        "id": "tngwjFLxXeVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the FST: restore the corpus text\n",
        "!farprintstrings earnest.far > earnest_2.txt"
      ],
      "metadata": {
        "id": "STkV9rMhX1FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract (non-normalized) n-gram counts from the compiled corpus\n",
        "!ngramcount --order=2 earnest.far earnest.cnts\n",
        "\n",
        "# Create a normalized and smoothed n-gram language model\n",
        "!ngrammake earnest.cnts earnest.mod\n",
        "\n",
        "!ngraminfo earnest.mod"
      ],
      "metadata": {
        "id": "2G7KqiHmbyKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model: generate a text\n",
        "!ngramrandgen earnest.mod | farprintstrings"
      ],
      "metadata": {
        "id": "ePAI5kFCcbb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ngrammerge - for model interpolation\n",
        "# ngramshrink - for model pruning\n",
        "# ngramperplexity - for model evaluation"
      ],
      "metadata": {
        "id": "I8yLg_FCdKQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Serialize the model in the standard ARPA format\n",
        "!ngramprint --ARPA earnest.mod earnest.ARPA"
      ],
      "metadata": {
        "id": "9lh0aKQVdfvP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}