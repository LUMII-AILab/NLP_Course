{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LUMII-AILab/NLP_Course/blob/main/notebooks/BSSDH2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Acquiring plain-text data for the corpus"
      ],
      "metadata": {
        "id": "xXCn7YyLyYrv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting the source documents"
      ],
      "metadata": {
        "id": "vsiXCG2X8th7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "id": "yEfobOGvHQ89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "uKYucU2w84Ch"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Via RSS feeds"
      ],
      "metadata": {
        "id": "jaUL3Vn3DpBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider [Europe Media Monitor](https://emm.newsbrief.eu) feeds:\n",
        "\n",
        "* [Current top 10 stories](https://emm.newsbrief.eu/NewsBrief/clusteredition/en/latest_en.html) (in English) ⇒ [machine-readable feed](https://emm.newsbrief.eu/rss/rss?type=rtn&language=en&duplicates=false) (RSS/XML)\n",
        "* [Biggest 10 Stories Over Last 24h](https://emm.newsbrief.eu/NewsBrief/clusteredition/en/24hrs_en.html) ⇒ [machine-readable feed](https://emm.newsbrief.eu/rss/rss?type=24hrs&language=en&duplicates=false) (RSS/XML)\n",
        "\n",
        "The Really Simple Syndication (RSS) standard and its XML format: https://www.w3schools.com/xml/xml_rss.asp\n",
        "\n",
        "The Python feedparser library: https://feedparser.readthedocs.io"
      ],
      "metadata": {
        "id": "bXrY-K99LG0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install feedparser"
      ],
      "metadata": {
        "id": "wl4j3-f_HTjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import feedparser\n",
        "\n",
        "from urllib.parse import urlparse\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "ADe9jBLCDx5U"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LANG = 'en'\n",
        "\n",
        "url_current = f'https://emm.newsbrief.eu/rss/rss?type=rtn&language={LANG}&duplicates=false'\n",
        "url_last24h = f'https://emm.newsbrief.eu/rss/rss?type=24hrs&language={LANG}&duplicates=false'\n",
        "\n",
        "feed = feedparser.parse(url_current)\n",
        "\n",
        "LINKS = [entry.link for entry in feed.entries]\n",
        "\n",
        "for link in LINKS: print(link)\n",
        "print(len(LINKS))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WOt9U1fbM-p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter = 'telegraph.co.uk'\n",
        "\n",
        "FILTERED_LINKS = [link for link in LINKS if filter in link]\n",
        "\n",
        "for link in FILTERED_LINKS: print(link)\n",
        "print(len(FILTERED_LINKS))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xElRh4QtUITn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data analysis"
      ],
      "metadata": {
        "id": "MZnrkHQoxkJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "domains = [urlparse(link).netloc for link in LINKS]\n",
        "\n",
        "frequencies = Counter(domains)\n",
        "\n",
        "for domain, count in frequencies.items():\n",
        "    print(f'{domain}: {count}')"
      ],
      "metadata": {
        "id": "F46J1fhMZmoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domains = [urlparse(link).netloc for link in LINKS]\n",
        "\n",
        "frequencies = Counter(domains)\n",
        "\n",
        "pruned = {domain: count for domain, count in frequencies.items() if count > 1}\n",
        "\n",
        "for domain, count in Counter(pruned).most_common():\n",
        "    print(f'{domain}: {count}')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lExc8BDSWgYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Via web crawling"
      ],
      "metadata": {
        "id": "_5fjeWCeDydF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iUiOuq3gD3g-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting useful content"
      ],
      "metadata": {
        "id": "CMKGfr8I84o7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4"
      ],
      "metadata": {
        "id": "WFWiuoSPG5I8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import requests\n",
        "import json"
      ],
      "metadata": {
        "id": "NesLQt-A9Qx-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_plain_text(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    paragraphs = soup.find_all('p')\n",
        "    text = '\\n'.join([p.get_text() for p in paragraphs])\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "xzhMiaKGdLO4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "\n",
        "for link in FILTERED_LINKS:\n",
        "    content = extract_plain_text(link)\n",
        "    print(content[:140], '\\n' + '='*140)\n",
        "\n",
        "    article = {\n",
        "        'language': LANG,\n",
        "        'domain': urlparse(link).netloc,\n",
        "        'link': link,\n",
        "        'text': content\n",
        "    }\n",
        "\n",
        "    dataset.append(article)\n",
        "\n",
        "with open('corpus.json', 'w', encoding='utf-8') as json_file:\n",
        "    json.dump(dataset, json_file, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jR5j6cr0a4u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some challenges"
      ],
      "metadata": {
        "id": "qrIREjte-kRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Messy HTML source code"
      ],
      "metadata": {
        "id": "TRPQUoR7-riX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "THnpgAll-xbT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PDF documents"
      ],
      "metadata": {
        "id": "7wEVdJ5R-yYP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o6AxU_oJ_pu9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating an annotated text corpus"
      ],
      "metadata": {
        "id": "4axMbGt9yf_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Syntactic parsing"
      ],
      "metadata": {
        "id": "vfDny89IAAz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Documentation:\n",
        "* Available models per language: https://stanfordnlp.github.io/stanza/models.html\n",
        "* Supported processors and pipelines: https://stanfordnlp.github.io/stanza/pipeline.html\n",
        "* Data objects: https://stanfordnlp.github.io/stanza/data_objects.html"
      ],
      "metadata": {
        "id": "63cEhuXjlK8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stanza"
      ],
      "metadata": {
        "id": "j4NQ9FPCjydA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza"
      ],
      "metadata": {
        "id": "ysatLmrbw83K"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stanza.download('en')"
      ],
      "metadata": {
        "id": "PGpeuW6vw_63",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NLP_PIPE = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse')"
      ],
      "metadata": {
        "id": "ev145Pm9xV3P",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CORPUS = []\n",
        "\n",
        "with open('corpus.json', 'r', encoding='utf-8') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "    for article in data:\n",
        "        CORPUS.append({\n",
        "            'language': article['language'],\n",
        "            'domain': article['domain'],\n",
        "            'link': article['link'],\n",
        "            'document': NLP_PIPE(article['text'])\n",
        "        })"
      ],
      "metadata": {
        "id": "jhwiF1zopORQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CoNLL-U output"
      ],
      "metadata": {
        "id": "RZKlEGaGosip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Format: https://universaldependencies.org/docs/format.html"
      ],
      "metadata": {
        "id": "gOtgL5Igz890"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('corpus.conllu', 'w', encoding='utf-8') as conllu_file:\n",
        "    for article in CORPUS:\n",
        "\n",
        "        for s in article['document'].sentences:\n",
        "            conllu_file.write(f'# text = {s.text}\\n')\n",
        "\n",
        "            for w in s.words:\n",
        "                conllu_file.write(\n",
        "                    f'{w.id}\\t'\n",
        "                    f'{w.text}\\t'\n",
        "                    f'{w.lemma}\\t'\n",
        "                    f'{w.upos}\\t'\n",
        "                    '_\\t'\n",
        "                    '_\\t'\n",
        "                    f'{w.head}\\t'\n",
        "                    f'{w.deprel}\\t'\n",
        "                    '_\\t'\n",
        "                    '_\\n'\n",
        "                )\n",
        "\n",
        "            conllu_file.write(\"\\n\")"
      ],
      "metadata": {
        "id": "I_9DNHfoy8Ru"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VERT output"
      ],
      "metadata": {
        "id": "GBFvgkSHO3mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('corpus.vert', 'w', encoding='utf-8') as vert_file:\n",
        "    for article in CORPUS:\n",
        "        vert_file.write(f'<doc>\\n')\n",
        "        for s in article['document'].sentences:\n",
        "            vert_file.write(f'<s>\\n')\n",
        "\n",
        "            for w in s.words:\n",
        "                vert_file.write(\n",
        "                    f'{w.text}\\t'\n",
        "                    f'{w.upos}\\t'\n",
        "                    f'{w.lemma}\\t'\n",
        "                    '_\\t'\n",
        "                    '_\\t'\n",
        "                    '_\\t'\n",
        "                    '_\\t'\n",
        "                    '_\\t'\n",
        "                    '_\\n'\n",
        "                )\n",
        "            vert_file.write(\"</s>\\n\")\n",
        "        vert_file.write(\"</doc>\\n\")"
      ],
      "metadata": {
        "id": "tHfx5cp3pKsy"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}